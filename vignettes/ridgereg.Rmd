---
title: "ridgereg"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ridgereg}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(BonusLab)
library(leaps)
library(Metrics)
library(MASS)
library(knitr)
```


```{r}
# Load data
data("BostonHousing")
set.seed(3456)

# Split data into test and train
trainIndex <- caret::createDataPartition(BostonHousing$crim, p = .8, 
                                  list = FALSE, 
                                  times = 1)
BostonTrain <- BostonHousing[ trainIndex,]
BostonTest  <- BostonHousing[-trainIndex,]
```



## Linear regression model with forward selection of covariates
```{r}
set.seed(123)
fit0 <- lm(medv~1, data=BostonTrain)
fit1 <- caret::train(medv~.,
              data = BostonTrain,
              method = "leapForward",
              tuneGrid = data.frame(nvmax=14),
              )
summary(fit1)
```

Just to be sure that the chosen model is better than a model without parameters, RMSE will be compared.
```{r}
RMSE_boston <- function(model, train=TRUE){
  if(train==FALSE){
    data <- BostonTest
  } else if (train==TRUE){
    data <- BostonTrain
  }
  actual <- data$medv
  pred <- predict(model, data)
  
  return(sqrt(sum((pred-actual)^2/length(actual))))
}
```

```{r}
data.frame(RMSE_boston(fit0, train=TRUE)) # Only intercept
data.frame(RMSE_boston(fit1, train=TRUE))
```
Since RMSE is higher for the model with only intercept, the other model is chosen as the best one.


```{r, echo=FALSE}
rmse1<-data.frame(RMSE_boston(fit1, train=TRUE))
colnames(rmse1)<-"RMSE train data"
```


```{r, echo=TRUE}
kable(rmse1)
```



## Ridge regression model using ridgereg()







